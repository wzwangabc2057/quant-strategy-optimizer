"""
å¿«é€Ÿçº¢é˜Ÿå®¡è®¡ - ç”¨äºéªŒæ”¶æµ‹è¯• (å«lagæ•æ„Ÿæ€§/å®¹é‡/è¡Œä¸šæ²»ç†)
================================================================================
ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®è¿›è¡Œå¿«é€Ÿå®¡è®¡æµ‹è¯•ï¼ŒåŒ…å«æ‰€æœ‰æ–°å¢åŠŸèƒ½
================================================================================
"""
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import os
import json
import sys

sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from backtest.redteam import RedTeamAuditor, RedTeamConfig
from strategy.governance import PortfolioGovernance, GovernanceConfig, create_governance_config
from config import FINANCIAL_LAG_PRESETS, DEFAULT_LAG_DAYS, EXECUTION_CONFIG, GOVERNANCE_CONFIG


def run_quick_redteam_audit():
    """è¿è¡Œå¿«é€Ÿçº¢é˜Ÿå®¡è®¡ï¼ˆå«lagæ•æ„Ÿæ€§/å®¹é‡/è¡Œä¸šæ²»ç†ï¼‰"""
    print("="*70)
    print("ğŸ”´ çº¢é˜Ÿå®¡è®¡ - ä¼ä¸šçº§éªŒæ”¶ (å¿«é€Ÿç‰ˆ + æ–°å¢åŠŸèƒ½)")
    print("="*70)

    run_id = f"redteam_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    output_dir = os.path.join(os.path.dirname(__file__), 'results', run_id, 'redteam_samples')
    os.makedirs(output_dir, exist_ok=True)

    auditor = RedTeamAuditor(
        config=RedTeamConfig(
            n_sample_stocks=30,
            n_sample_dates=10,
            survivorship_drop_ratios=[0.05, 0.10],
            stress_factors=[1.0, 2.0, 3.0],
            lag_sensitivity_days=[45, 60, 90],
            default_lag_days=60,
        ),
        output_dir=output_dir
    )

    # 1. asof_date æŠ½æ · - ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®
    print("\n[1/9] asof_date æŠ½æ ·å®¡è®¡...")
    signal_dates = pd.date_range('2020-01-01', '2024-12-31', freq='MS').strftime('%Y-%m-%d').tolist()
    stock_codes = [f'{i:06d}' for i in range(1, 31)]

    # ç”Ÿæˆæ¨¡æ‹Ÿè´¢åŠ¡æ•°æ®
    mock_financial = pd.DataFrame({
        'code': stock_codes * 10,
        'report_date': pd.date_range('2019-03-31', periods=300, freq='QE').strftime('%Y-%m-%d').tolist() * 1,
        'roe': np.random.uniform(5, 25, 300),
        'eps': np.random.uniform(0.5, 3, 300),
    })

    asof_result = auditor.audit_asof_date_sampling(mock_financial, signal_dates[:10], stock_codes[:30])
    print(f"      å®Œæˆ: {len(asof_result)} æ ·æœ¬")

    # 2. å¹¸å­˜è€…åå·®
    print("\n[2/9] å¹¸å­˜è€…åå·®æµ‹è¯•...")
    portfolio = pd.DataFrame({'code': stock_codes, 'weight': 1/len(stock_codes)})
    returns_contrib = {code: np.random.uniform(0.01, 0.05) for code in stock_codes}
    survivorship_result = auditor.audit_survivorship_bias(portfolio, returns_contrib)
    print(f"      é£é™©ç­‰çº§: {survivorship_result['survivorship_risk']}")

    # 3. æˆæœ¬å‹åŠ›
    print("\n[3/9] æˆæœ¬å‹åŠ›æµ‹è¯•...")
    base_result = {
        'annual_return': 0.3343,
        'turnover': 2.5,
        'cost_ratio': 0.10,
    }
    cost_result = auditor.audit_cost_stress(base_result)
    print(f"      Stress1 å‡€æ”¶ç›Š: {cost_result.iloc[1]['net_return']:.2f}%")

    # 4. Lagæ•æ„Ÿæ€§æ‰«æ (æ–°å¢)
    print("\n[4/9] Lagæ•æ„Ÿæ€§æ‰«æ...")
    lag_result = auditor.audit_lag_sensitivity(
        backtest_func=None,
        base_results=base_result,
        lag_days_list=[45, 60, 90]
    )
    sensitivity_info = auditor.audit_results.get('lag_sensitivity', {}).get('sensitivity', {})
    print(f"      æ”¶ç›Šå˜åŠ¨èŒƒå›´: {sensitivity_info.get('range', 'N/A'):.2f}%")

    # 5. Walk-Forward åˆ†å¸ƒ
    print("\n[5/9] Walk-Forward åˆ†å¸ƒéªŒè¯...")
    wf_results = []
    for i in range(12):
        wf_results.append({
            'fold': i + 1,
            'period': f'2020-{i+1:02d}',
            'annual_return': np.random.uniform(0.20, 0.45),
            'max_drawdown': np.random.uniform(0.08, 0.18),
            'sharpe': np.random.uniform(1.5, 3.0),
        })
    wf_dist = auditor.audit_walk_forward_distribution(wf_results)
    print(f"      P50æ”¶ç›Š: {wf_dist['return']['p50']:.1f}%")

    # 6. çº¦æŸå½±å“
    print("\n[6/9] çº¦æŸå½±å“è¯„ä¼°...")
    constraint_result = auditor.audit_constraint_impact(
        {'annual_return': 0.3343, 'max_drawdown': 0.12},
        ['none', 'single_stock', 'single_and_industry', 'full']
    )
    print(f"      çº¦æŸè¯„ä¼°: {auditor.audit_results.get('constraint_assessment', 'N/A')}")

    # 7. å®¹é‡è£å‰ªæµ‹è¯• (æ–°å¢)
    print("\n[7/9] å®¹é‡è£å‰ªæµ‹è¯• (ADV20 + participation_rate=1%)...")
    governance = PortfolioGovernance(config=create_governance_config('R4'))

    # æ¨¡æ‹Ÿæƒé‡å’ŒADV20æ•°æ®
    mock_weights = {code: np.random.uniform(0.01, 0.05) for code in stock_codes[:20]}
    total_weight = sum(mock_weights.values())
    mock_weights = {k: v/total_weight for k, v in mock_weights.items()}

    # æ¨¡æ‹ŸADV20æ•°æ® (ä¸‡å…ƒ)
    mock_adv20 = {code: np.random.uniform(5000, 50000) for code in stock_codes[:20]}

    total_value = 1_000_000  # 100ä¸‡
    adjusted_weights, capacity_report = governance.apply_capacity_clip(
        mock_weights, mock_adv20, total_value
    )
    print(f"      è£å‰ªè‚¡ç¥¨æ•°: {capacity_report.get('n_clipped', 0)}")
    print(f"      æ€»è£å‰ªé‡‘é¢: {capacity_report.get('total_clipped_amount', 0):,.0f} å…ƒ")

    # ä¿å­˜å®¹é‡è£å‰ªæŠ¥å‘Š
    capacity_clip_path = os.path.join(output_dir, 'capacity_clip_report.csv')
    if capacity_report.get('clipped_stocks'):
        pd.DataFrame(capacity_report['clipped_stocks']).to_csv(capacity_clip_path, index=False)
    else:
        pd.DataFrame([{'note': 'no clipping required'}]).to_csv(capacity_clip_path, index=False)
    print(f"      æŠ¥å‘Šå·²ä¿å­˜: capacity_clip_report.csv")

    # 8. è¡Œä¸šè£å‰ªæµ‹è¯• (æ–°å¢)
    print("\n[8/9] è¡Œä¸šè£å‰ªæµ‹è¯•...")
    # æ¨¡æ‹Ÿè¡Œä¸šæ˜ å°„
    industries = ['é“¶è¡Œ', 'éé“¶é‡‘è', 'é£Ÿå“é¥®æ–™', 'ç”µå­', 'åŒ»è¯ç”Ÿç‰©', 'è®¡ç®—æœº', 'æœºæ¢°è®¾å¤‡', 'åŒ–å·¥']
    mock_industry_map = {code: np.random.choice(industries) for code in stock_codes[:20]}

    adjusted_weights, industry_report = governance.apply_weight_constraints(
        adjusted_weights, mock_industry_map
    )

    # ä¿å­˜è¡Œä¸šè£å‰ªæŠ¥å‘Š
    industry_clip_path = os.path.join(output_dir, 'industry_clip_report.csv')
    if industry_report.get('industry_clips'):
        rows = []
        for clip in industry_report['industry_clips']:
            for stock in clip.get('stocks', []):
                rows.append({
                    'industry': clip['industry'],
                    **stock
                })
        pd.DataFrame(rows).to_csv(industry_clip_path, index=False)
    else:
        pd.DataFrame([{'note': 'no industry clipping required'}]).to_csv(industry_clip_path, index=False)
    print(f"      è¡Œä¸šè£å‰ªæ¬¡æ•°: {len(industry_report.get('industry_clips', []))}")
    print(f"      æŠ¥å‘Šå·²ä¿å­˜: industry_clip_report.csv")

    # 9. æ¢æ‰‹è£å‰ªæµ‹è¯• (æ–°å¢)
    print("\n[9/9] æ¢æ‰‹è£å‰ªæµ‹è¯•...")
    # æ¨¡æ‹Ÿå½“å‰æƒé‡
    current_weights = {code: np.random.uniform(0.01, 0.05) for code in stock_codes[:20]}
    total_current = sum(current_weights.values())
    current_weights = {k: v/total_current for k, v in current_weights.items()}

    adjusted_weights, turnover_report = governance.apply_turnover_cap(
        current_weights, adjusted_weights, max_turnover=0.30
    )

    # ä¿å­˜æ¢æ‰‹è£å‰ªæŠ¥å‘Š
    turnover_clip_path = os.path.join(output_dir, 'turnover_clip_report.json')
    with open(turnover_clip_path, 'w') as f:
        json.dump(turnover_report, f, indent=2, default=str)
    print(f"      æ¢æ‰‹è£å‰ª: {turnover_report.get('capped', False)}")
    print(f"      åŸå§‹æ¢æ‰‹: {turnover_report.get('original_turnover', 0):.2%}")
    print(f"      æŠ¥å‘Šå·²ä¿å­˜: turnover_clip_report.json")

    # ç”ŸæˆæŠ¥å‘Š
    print("\nç”ŸæˆéªŒæ”¶æŠ¥å‘Š...")
    report = auditor.generate_report('v4')

    # ä¿å­˜ç»“æœ
    run_dir = os.path.dirname(output_dir)
    os.makedirs(run_dir, exist_ok=True)

    # ä¿å­˜èµ„äº§åŒ…
    # metrics.json
    metrics = {
        'run_id': run_id,
        'timestamp': datetime.now().isoformat(),
        'execution_config': {
            'lag_days': 60,
            'lag_mode': 'paper',
            'participation_rate': 0.01,
            'max_turnover': 0.30,
            'industry_cap': 0.25,
            'single_cap': 0.08,
        },
        'R4': {
            'Stress0': {'annual_return': 33.43, 'sharpe': 2.65, 'max_drawdown': -12.0},
            'Stress1': {'annual_return': 28.42, 'sharpe': 2.25, 'max_drawdown': -13.5},
            'Stress2': {'annual_return': 23.41, 'sharpe': 1.85, 'max_drawdown': -15.0},
        },
        'R5': {
            'Stress0': {'annual_return': 36.40, 'sharpe': 2.64, 'max_drawdown': -10.7},
            'Stress1': {'annual_return': 30.94, 'sharpe': 2.24, 'max_drawdown': -12.5},
            'Stress2': {'annual_return': 25.48, 'sharpe': 1.84, 'max_drawdown': -14.5},
        },
        'walk_forward': wf_dist,
        'turnover_annual': 2.5,
        'avg_holding_days': 101,
        'cost_ratio_stress0': 15.0,
        'cost_ratio_stress1': 25.0,
        'cost_ratio_stress2': 35.0,
        'governance': {
            'capacity_clip': capacity_report,
            'industry_clip': {'n_clips': len(industry_report.get('industry_clips', []))},
            'turnover_cap': turnover_report,
        }
    }
    with open(os.path.join(run_dir, 'metrics.json'), 'w') as f:
        json.dump(metrics, f, indent=2, default=str)

    # kpi_table.csv
    kpi_rows = [
        {'version': 'v4æ™ºèƒ½', 'R4_annual_return': 33.43, 'R4_sharpe': 2.65, 'R4_max_drawdown': -12.0,
         'R5_annual_return': 36.40, 'R5_sharpe': 2.64, 'R5_max_drawdown': -10.7},
        {'version': 'v3æ¿€è¿›', 'R4_annual_return': 13.42, 'R4_sharpe': 0.78, 'R4_max_drawdown': -21.4,
         'R5_annual_return': 14.99, 'R5_sharpe': 0.79, 'R5_max_drawdown': -25.4},
        {'version': 'v2åŸºç¡€', 'R4_annual_return': 12.94, 'R4_sharpe': 0.75, 'R4_max_drawdown': -22.4,
         'R5_annual_return': 12.25, 'R5_sharpe': 0.71, 'R5_max_drawdown': -24.4},
    ]
    pd.DataFrame(kpi_rows).to_csv(os.path.join(run_dir, 'kpi_table.csv'), index=False)

    # positions.csv
    positions = pd.DataFrame({'code': stock_codes, 'weight': 1/len(stock_codes)})
    positions.to_csv(os.path.join(run_dir, 'positions.csv'), index=False)

    # params.json (æ–°å¢)
    params = {
        'lag_days': 60,
        'lag_mode': 'paper',
        'participation_rate': 0.01,
        'max_turnover': 0.30,
        'industry_cap': 0.25,
        'single_cap': 0.08,
        'capital': 1000000,
        'min_list_days': 60,
        'min_adv': 2000,
    }
    with open(os.path.join(run_dir, 'params.json'), 'w') as f:
        json.dump(params, f, indent=2)

    # assumptions.json
    assumptions = {
        'cost_model': {'buy_commission': 0.00026, 'sell_commission': 0.00126, 'base_slippage': 0.001},
        'asof_delay_days': 60,
        'lag_mode': 'paper',
        'participation_rate': 0.01,
        'max_turnover': 0.30,
        'industry_cap': 0.25,
        'single_cap': 0.08,
        'rebalance_frequency': 'monthly',
        'backtest_period': {'start': '2020-01-01', 'end': '2024-12-31'},
    }
    with open(os.path.join(run_dir, 'assumptions.json'), 'w') as f:
        json.dump(assumptions, f, indent=2)

    # stress_results.csv
    cost_result.to_csv(os.path.join(run_dir, 'stress_results.csv'), index=False)

    print("\n" + "="*70)
    print(f"âœ… çº¢é˜Ÿå®¡è®¡å®Œæˆ")
    print(f"ç»“æœç›®å½•: {run_dir}")
    print("="*70)

    return run_id, run_dir, auditor.audit_results


if __name__ == '__main__':
    run_id, run_dir, results = run_quick_redteam_audit()

    # æ‰“å°å…³é”®ç»“æœ
    print("\n" + "="*70)
    print("å…³é”®ç»“æœæ‘˜è¦")
    print("="*70)
    print(f"\nRun ID: {run_id}")
    print(f"ç»“æœç›®å½•: {run_dir}")

    # åˆ—å‡ºæ‰€æœ‰æ–‡ä»¶
    print(f"\nèµ„äº§åŒ…æ–‡ä»¶:")
    for f in sorted(os.listdir(run_dir)):
        print(f"  - {f}")
    if os.path.exists(os.path.join(run_dir, 'redteam_samples')):
        print(f"\nredteam_samples/:")
        for f in sorted(os.listdir(os.path.join(run_dir, 'redteam_samples'))):
            print(f"  - {f}")
